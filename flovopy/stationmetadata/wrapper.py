import os
from obspy import UTCDateTime
from obspy.core.inventory import Inventory, Network, Station, Channel, Site, read_inventory
from flovopy.stationmetadata.build import build_inventory_from_table, merge_inventories
#from flovopy.stationmetadata.utils import apply_coordinates_from_csv
import traceback

def get_stationXML_inventory(
    xmlfile: str,
    excel_file: str,
    sheet_name: str = 'ksc_stations_master',
    infrabsu_xml: str = None,
    nrl_path: str = None,
    overwrite: bool = False,
    verbose: bool = False,
) -> Inventory:
    """
    Load or build a StationXML Inventory from an Excel metadata table.

    If the XML file exists and `overwrite=False`, the inventory is loaded from file.
    Otherwise, a new inventory is built from the Excel sheet using the NRL.

    Parameters:
    -----------
    xmlfile : str
        Path to output or existing StationXML file.
    excel_file : str
        Path to the Excel metadata file (e.g., KSC master station sheet).
    sheet_name : str
        Name of the Excel sheet to load (default: 'ksc_stations_master').
    infrabsu_xml : str, optional
        Optional base StationXML containing predefined infraBSU sensor responses.
    nrl_path : str, optional
        Path to a local NRL directory (if None, uses remote IRIS NRL).
    overwrite : bool, optional
        If True, rebuild the inventory even if xmlfile already exists.
    verbose : bool, optional
        If True, print detailed progress messages.

    Returns:
    --------
    inv : obspy.core.inventory.Inventory
        The loaded or newly built inventory.
    """
    if os.path.isfile(xmlfile) and not overwrite:
        inv = read_inventory(xmlfile)
        if verbose:
            print(f"[INFO] Loaded existing StationXML: {xmlfile}")
    else:
        if verbose:
            print("[INFO] Creating new inventory from Excel metadata...")

        try:
            inv = build_inventory_from_table(
                path=excel_file,
                sheet_name=sheet_name,
                nrl_path=nrl_path,
                verbose=verbose,
                infrabsu_xml=infrabsu_xml
            )
        except Exception as e:
            print(f"[ERROR] Failed to build inventory from {excel_file}: {e}")
            traceback.print_exc()
            raise e

        try:
            inv = merge_inventories(inv)
        except Exception as e:
            print(f"[ERROR] Failed to merge inventories: {e}")
            traceback.print_exc()
            raise e 
        
        try:
            inv.write(xmlfile, format='STATIONXML', validate=True)
        except Exception as e:
            print(f"[ERROR] Failed to write StationXML to {xmlfile}: {e}")
            traceback.print_exc()
            raise e 

        if verbose:
            print(f"[OK] Wrote StationXML to {xmlfile}")

    return inv

'''
def merge_duplicate_stations_and_patch_site(inventory):
    """
    Merges stations with the same code and patches missing site metadata.

    Parameters:
    -----------
    inventory : obspy.core.inventory.Inventory
        Inventory object that may contain duplicate stations.

    Returns:
    --------
    merged_inventory : obspy.core.inventory.Inventory
        Inventory with one station per code and patched site metadata.
    """
    merged_networks = []

    for net in inventory:
        station_map = defaultdict(list)
        for sta in net:
            station_map[sta.code].append(sta)

        new_stations = []
        for code, stations in station_map.items():
            all_channels = []
            for sta in stations:
                all_channels.extend(sta.channels)

            merged_station = Station(
                code=code,
                latitude=stations[0].latitude,
                longitude=stations[0].longitude,
                elevation=stations[0].elevation,
                channels=all_channels,
                site=stations[0].site or Site(
                    name=f"{code}_SITE",
                    description=f"Autogenerated site description for {code}"
                ),
                creation_date=stations[0].creation_date,
                start_date=stations[0].start_date,
                end_date=stations[0].end_date
            )

            if not merged_station.site.name:
                merged_station.site.name = f"{code}_SITE"
            if not merged_station.site.description:
                merged_station.site.description = f"Autogenerated site description for {code}"

            new_stations.append(merged_station)

        merged_networks.append(Network(code=net.code, stations=new_stations))

    return Inventory(networks=merged_networks, source=inventory.source)
'''

def responses2inventory(
    net, sta, loc, fsamp, responses,
    lat=None, lon=None, elev=None, depth=None,
    start_date=UTCDateTime(1900, 1, 1),
    end_date=UTCDateTime(2100, 1, 1)
):
    """
    Builds an ObsPy Inventory for a single station from a dictionary of channel responses.

    Parameters:
    -----------
    net : str
        Network code.
    sta : str
        Station code.
    loc : str
        Location code (usually 2 characters).
    fsamp : float
        Sampling rate in Hz.
    responses : dict
        Dictionary mapping channel codes (e.g. 'HDF') to ObsPy Response objects.
    lat, lon, elev, depth : float
        Station coordinates and depth (optional).
    start_date, end_date : obspy.UTCDateTime
        Time span of the metadata.

    Returns:
    --------
    inventory : obspy.core.inventory.Inventory
        A single-station Inventory object.
    """
    channels = []
    for chan, responseObj in responses.items():
        channel = Channel(
            code=chan,
            location_code=loc,
            latitude=lat,
            longitude=lon,
            elevation=elev,
            depth=depth,
            sample_rate=fsamp,
            start_date=start_date,
            end_date=end_date,
            response=responseObj
        )
        channels.append(channel)

    station = Station(
        code=sta,
        latitude=lat,
        longitude=lon,
        elevation=elev,
        creation_date=UTCDateTime(),
        channels=channels,
        start_date=start_date,
        end_date=end_date
    )

    network = Network(code=net, stations=[station])
    inventory = Inventory(networks=[network], source="USF_instrument_responses.py")

    return inventory

if __name__ == "__main__":
    import os
    from pathlib import Path
    import tempfile
    import pandas as pd

    print("[TEST] get_stationXML_inventory — end-to-end smoke test")

    # Temp working dir
    workdir = Path(tempfile.gettempdir()) / "flovopy_stationxml_test"
    workdir.mkdir(parents=True, exist_ok=True)

    # Where to write the StationXML result
    out_xml = workdir / "test_inventory.stationxml"

    # Build a tiny metadata table as CSV (so we don't need a real Excel file)
    # Columns expected by build_inventory_from_table -> build_inventory_from_dataframe -> sensor_type_dispatch
    rows = [
        # RBOOM (local template path; no NRL)
        dict(network="AM", station="RBTEST",  location="00", channel="HDF",
             sensor="RBOOM", datalogger="RBOOM", lat=28.5, lon=-80.6, elev=3.0, depth=0.0,
             fsamp=100.0, vpp=40, ondate="2024-01-01", offdate="2100-01-01"),
        # RS1D v6 (local template path; no NRL)
        dict(network="AM", station="RS1D6T", location="00", channel="EHZ",
             sensor="RS1D", datalogger="RS1D", lat=28.5, lon=-80.6, elev=3.0, depth=0.0,
             fsamp=100.0, vpp=40, ondate="2024-01-01", offdate="2100-01-01"),
    ]

    # Optionally include an infraBSU+Centaur example (hits remote NRL unless you’ve cached)
    if os.environ.get("INCLUDE_INFRA", "0") == "1":
        rows.append(
            dict(network="1R", station="INFRA1", location="10", channel="HDF",
                 sensor="infraBSU", datalogger="Centaur", lat=28.5721, lon=-80.6480, elev=3.0, depth=0.0,
                 fsamp=100.0, vpp=40, ondate="2024-01-01", offdate="2100-01-01")
        )

    df = pd.DataFrame(rows)
    csv_path = workdir / "test_metadata.csv"
    df.to_csv(csv_path, index=False)
    print(f"[INFO] Wrote test CSV: {csv_path}")

    # Run once (should build fresh file)
    print("\n[STEP 1] Build new inventory (overwrite=True)")
    inv = get_stationXML_inventory(
        xmlfile=str(out_xml),
        excel_file=str(csv_path),          # build_* functions accept CSV path as well
        sheet_name="ksc_stations_master",  # ignored for CSV
        infrabsu_xml=None,                 # provide a path to prebuilt infraBSU template if you want
        nrl_path=None,                     # set if you have a compatible local NRLv1 (rare now)
        overwrite=True,
        verbose=True,
    )
    print(inv)

    # Run again without overwrite (should load from disk, not rebuild)
    print("\n[STEP 2] Load existing inventory (overwrite=False)")
    inv2 = get_stationXML_inventory(
        xmlfile=str(out_xml),
        excel_file=str(csv_path),
        overwrite=False,
        verbose=True,
    )
    print(inv2)

    print(f"\n[OK] StationXML is at: {out_xml}")
    print("[NOTE] To include an infraBSU+Centaur test row (will query the remote NRL), set INCLUDE_INFRA=1.")