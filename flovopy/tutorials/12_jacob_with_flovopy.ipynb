{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f51f37c",
   "metadata": {},
   "source": [
    "# Amplitude Source Location (ASL) - Recreating Jacob's notebook with flovopy\n",
    "\n",
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08fc811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from obspy import read_inventory, UTCDateTime\n",
    "from importlib import reload\n",
    "from flovopy.asl.wrappers import run_single_event, find_event_files, run_all_events\n",
    "from flovopy.processing.sam import VSAM, DSAM \n",
    "from flovopy.asl.config import ASLConfig, tweak_config\n",
    "\n",
    "# Core ASL + utilities\n",
    "from flovopy.asl.asl import ASL\n",
    "from flovopy.asl.wrappers import asl_sausage\n",
    "from flovopy.asl.grid import Grid, make_grid\n",
    "from flovopy.asl.distances import compute_or_load_distances, distances_signature\n",
    "from flovopy.asl.ampcorr import AmpCorr, AmpCorrParams\n",
    "from flovopy.asl.misfit import StdOverMeanMisfit, R2DistanceMisfit, LinearizedDecayMisfit\n",
    "from flovopy.asl.map import topo_map\n",
    "\n",
    "# --- Diagnostics / comparisons ---\n",
    "from flovopy.asl.compare import extract_asl_diagnostics, compare_asl_sources\n",
    "\n",
    "# --- Simulation helpers ---\n",
    "from flovopy.asl.simulate import simulate_SAM, plot_SAM, synthetic_source_from_grid\n",
    "\n",
    "# -------------------------- Config --------------------------\n",
    "# directories\n",
    "HOME = Path.home()\n",
    "DATA_DIR = HOME / 'Dropbox' / 'BRIEFCASE'/ 'SSADenver'  /'Jacob'\n",
    "\n",
    "# master files\n",
    "INVENTORY_XML   = DATA_DIR / \"6Q.xml\"\n",
    "\n",
    "REGION_DEFAULT = [-90.98, -90.78, 14.365, 14.49]\n",
    "DEM_DEFAULT = None\n",
    "\n",
    "# other parameters\n",
    "DIST_MODE = \"2d\"\n",
    "\n",
    "# Inventory of Montserrat stations\n",
    "INV     = read_inventory(INVENTORY_XML)\n",
    "print(f\"[INV] Networks: {len(INV)}  Stations: {sum(len(n) for n in INV)}  Channels: {sum(len(sta) for net in INV for sta in net)}\")\n",
    "\n",
    "MAT_FILE = DATA_DIR / \"outputfromReadMapData.mat\"\n",
    "MSEED_DIR = DATA_DIR / \"ClipMSEED\"                # directory containing MiniSEED\n",
    "\n",
    "\n",
    "'''\n",
    "SRTM_ASC_GZ = DATA_DIR / \"srtm_18_10.asc.gz\"      # optional background\n",
    "SRTM_CELL = 0.00083333333333333\n",
    "SRTM_XLL  = -95.0\n",
    "SRTM_YLL  = 10.0\n",
    "\n",
    "stations = ['FEJ1', 'FEC1', 'FEC2', 'FEC4']       # order must match sta rows\n",
    "\n",
    "# Seismo params\n",
    "sps = 200\n",
    "lc, hc = 1.0, 99.0                                # bandpass (Hz)\n",
    "pre_filt = (0.5, 0.8, 90.0, 100.0)                # for remove_response\n",
    "beta = 1250.0                                     # m/s, assumed wave speed\n",
    "m_slope = -1.0                                    # -1 body, -0.5 surface\n",
    "\n",
    "winlength_seconds = 10\n",
    "plot_limits_sec = (7500, 10000)\n",
    "t_start_sec = 8000\n",
    "t_end_sec   = 9200\n",
    "\n",
    "# Local-grid -> UTM offsets (apply BEFORE transforming to geographic)\n",
    "UTM_E_OFFSET = 715_901.84\n",
    "UTM_N_OFFSET = 1_584_182.68\n",
    "\n",
    "# CRS (example: UTM zone 15N; change if needed)\n",
    "CRS_UTM = CRS.from_epsg(32615)\n",
    "CRS_WGS84 = CRS.from_epsg(4326)\n",
    "TO_WGS84 = Transformer.from_crs(CRS_UTM, CRS_WGS84, always_xy=True)\n",
    "\n",
    "'''\n",
    "\n",
    "# Montserrat constants\n",
    "dome_location = {'lat': 14.475, 'lon':-90.88}\n",
    "print(\"Dome (assumed source) =\", dome_location)\n",
    "\n",
    "# define grid size and spacing\n",
    "GRID_SIZE_LAT_M = 18_000   \n",
    "GRID_SIZE_LON_M = 18_000  \n",
    "NODE_SPACING_M  = 50       \n",
    "\n",
    "\n",
    "gridobj = make_grid(\n",
    "    center_lat=dome_location[\"lat\"],\n",
    "    center_lon=dome_location[\"lon\"],\n",
    "    node_spacing_m=NODE_SPACING_M,\n",
    "    grid_size_lat_m=GRID_SIZE_LAT_M,\n",
    "    grid_size_lon_m=GRID_SIZE_LON_M,\n",
    "    dem=None,\n",
    ")\n",
    "print(gridobj)\n",
    "\n",
    "# Parameters to pass for making pygmt topo maps\n",
    "topo_kw = {\n",
    "    \"inv\": INV,\n",
    "    \"add_labels\": True,\n",
    "    \"cmap\": \"gray\",\n",
    "    \"region\": REGION_DEFAULT,\n",
    "    \"dem_tif\": DEM_DEFAULT,  # basemap shading from your GeoTIFF - but does not actually seem to use this unless topo_color=True and cmap=None\n",
    "    \"frame\": True,\n",
    "    \"dome_location\": dome_location,\n",
    "    \"topo_color\": False,\n",
    "}\n",
    "\n",
    "gridobj.plot(show=True, min_display_spacing=300, scale=2.0, topo_map_kwargs=topo_kw);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c3ae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from flovopy.asl.find_channels import run_find_channels, nodegrid_from_channels_dir\n",
    "\n",
    "DATA_DIR = Path.home() / \"Dropbox\" / \"BRIEFCASE\" / \"SSADenver\" / \"Jacob\"\n",
    "outdir = DATA_DIR / \"jacob_channels\"\n",
    "\n",
    "REGION = [-90.96, -90.80, 14.39, 14.51]  # tighter box around Fuego/Ceniza; tweak if needed\n",
    "\n",
    "# Run the pipeline using only supported args\n",
    "run_find_channels(\n",
    "    region=REGION_DEFAULT,\n",
    "    outdir=outdir,\n",
    "    earth_relief=\"01s\",\n",
    "    extra_args=[\n",
    "        \"--prep\",\n",
    "        \"--breach\",\n",
    "        \"--fa-percentile\", \"90\",   # try 85–92 if Ceniza is still thin\n",
    "        \"--min-cells\", \"60\",\n",
    "        \"--top-n\", \"60\",           # keep more channels, prune later\n",
    "        \"--min-len-m\", \"150\",      # don't prune too aggressively here\n",
    "        # \"--no-plots\",            # optional\n",
    "        # \"--no-nodegrid\",         # optional (we’ll build NodeGrid explicitly below)\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Build a NodeGrid directly from the outputs\n",
    "ng = nodegrid_from_channels_dir(outdir, approx_spacing_m=20.0)\n",
    "print(f\"NodeGrid nodes: {ng.node_lon.size}  spacing≈{ng.approx_spacing_m} m  dem_tag={ng.dem_tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f6e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_grid, mask2d, matches = ng.mask_grid_with_nodes(\n",
    "    gridobj,\n",
    "    k=12,            # broaden neighbor search a bit\n",
    "    max_m=40.0,      # allow 40 m snap distance\n",
    "    flatten_copy=True,\n",
    "    return_matches=True,\n",
    ")\n",
    "\n",
    "channels_grid.plot(\n",
    "    topo_map_kwargs=topo_kw,\n",
    "    symbol=\"c\", scale=2.0, fill=\"red\", force_all_nodes=True, show=True,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cedade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import subprocess, json, math\n",
    "import rasterio as rio\n",
    "from rasterio.features import shapes\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape, LineString\n",
    "from shapely.ops import linemerge\n",
    "from pyproj import CRS\n",
    "\n",
    "WBT = \"whitebox\"  # if your binary is `whitebox`, set WBT=\"whitebox\"\n",
    "\n",
    "def _run(cmd, cwd=None):\n",
    "    print(\"[cmd]\", \" \".join(cmd))\n",
    "    r = subprocess.run(cmd, cwd=cwd, capture_output=True, text=True)\n",
    "    if r.returncode != 0:\n",
    "        print(r.stdout); print(r.stderr)\n",
    "        raise RuntimeError(f\"cmd failed: {r.returncode}\")\n",
    "    return r.stdout\n",
    "\n",
    "def extract_streams_ceniza_friendly(\n",
    "    dem_utm_tif: Path, outdir: Path, summit_lon=-90.88, summit_lat=14.475,\n",
    "    fa_q=0.88, min_cells=40, min_len_m=1200, quadrant=(210, 270)  # SW wedge\n",
    "):\n",
    "    \"\"\"\n",
    "    DEM must be UTM meters. Produces:\n",
    "      - 04_fa_dinf.tif    (flow accumulation)\n",
    "      - 05_streams_bin.tif (binary mask)\n",
    "      - 05_streams_clean.tif (thinned + de-spurred)\n",
    "      - 05_streams.gpkg    (vectorized, pruned to quadrant & length)\n",
    "    \"\"\"\n",
    "    outdir = Path(outdir); outdir.mkdir(parents=True, exist_ok=True)\n",
    "    pntr = outdir/\"04_dinf_pntr.tif\"\n",
    "    fa   = outdir/\"04_fa_dinf.tif\"\n",
    "    streams_bin = outdir/\"05_streams_bin.tif\"\n",
    "    streams_thn = outdir/\"05_streams_clean.tif\"\n",
    "    streams_vec = outdir/\"05_streams.gpkg\"\n",
    "\n",
    "    # 1) Mild breach + D-Infinity pointer/FA\n",
    "    _run([WBT, f'--run=BreachDepressionsLeastCost', f'--dem={dem_utm_tif}', f'--output={outdir/\"03_dem_breached.tif\"}', '-v'])\n",
    "    dem_breached = outdir/\"03_dem_breached.tif\"\n",
    "    _run([WBT, f'--run=DInfPointer', f'--dem={dem_breached}', f'--output={pntr}', '-v'])\n",
    "    _run([WBT, f'--run=DInfFlowAccumulation', f'--dem={dem_breached}', f'--output={fa}', '--out_type=cells', '-v'])\n",
    "\n",
    "    # 2) Choose FA threshold from local histogram (cone flanks)\n",
    "    with rio.open(fa) as ds:\n",
    "        fa_arr = ds.read(1, masked=True)\n",
    "        # ignore nodata and very low FA\n",
    "        vals = np.asarray(fa_arr.compressed(), float)\n",
    "        vals = vals[vals >= min_cells]\n",
    "        thr  = np.quantile(vals, fa_q) if vals.size else float(min_cells)\n",
    "        print(f\"[FA] q={fa_q:.2f}  -> threshold ~ {thr:.1f} cells\")\n",
    "\n",
    "    # 3) Extract, thin, remove spurs (binary lines)\n",
    "    _run([WBT, f'--run=ExtractStreams', f'--flow_accum={fa}', f'--threshold={thr}',\n",
    "          f'--d8_pntr={pntr}', f'--output={streams_bin}', '-v'])\n",
    "    _run([WBT, f'--run=LineThinning', f'--i={streams_bin}', f'--output={streams_thn}', '-v'])\n",
    "    _run([WBT, f'--run=RemoveSpurs', f'--input={streams_thn}', f'--output={streams_thn}', '--iterations=2', '-v'])\n",
    "\n",
    "    # 4) Raster -> vector (and prune)\n",
    "    with rio.open(streams_thn) as ds:\n",
    "        mask = ds.read(1) > 0\n",
    "        shapes_iter = shapes(mask.astype(np.uint8), mask=None, transform=ds.transform)\n",
    "        lines = []\n",
    "        for geom, val in shapes_iter:\n",
    "            if val != 1:\n",
    "                continue\n",
    "            poly = shape(geom)\n",
    "            # skeleton pixels → we polygonize and then take boundaries; simpler: trace pixel centers:\n",
    "            # Here, take polygon boundary segments as proxy polylines\n",
    "            for seg in poly.boundary.geoms if hasattr(poly.boundary, \"geoms\") else [poly.boundary]:\n",
    "                if seg.length > 0:\n",
    "                    lines.append(seg)\n",
    "\n",
    "    if not lines:\n",
    "        print(\"[warn] no stream segments created.\"); return None\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(geometry=lines, crs=CRS.from_wkt(rio.open(dem_utm_tif).crs.wkt))\n",
    "    gdf[\"len_m\"] = gdf.length\n",
    "    gdf = gdf[gdf[\"len_m\"] >= float(min_len_m)]\n",
    "\n",
    "    # 5) Keep quadrant rays from summit (helps isolate Ceniza)\n",
    "    #    Compute azimuth at each segment midpoint relative to summit and keep within wedge.\n",
    "    from pyproj import Transformer\n",
    "    utm = CRS.from_wkt(rio.open(dem_utm_tif).crs.wkt)\n",
    "    to_utm = Transformer.from_crs(\"EPSG:4326\", utm, always_xy=True)\n",
    "    sx, sy = to_utm.transform(summit_lon, summit_lat)\n",
    "\n",
    "    def _azi(x0,y0,x1,y1):\n",
    "        return (math.degrees(math.atan2(x1-x0, y1-y0)) + 360) % 360\n",
    "\n",
    "    az0, az1 = quadrant\n",
    "    keep = []\n",
    "    for geom in gdf.geometry:\n",
    "        m = geom.interpolate(0.5, normalized=True)\n",
    "        ax = _azi(sx, sy, m.x, m.y)\n",
    "        if az0 <= az1:\n",
    "            ok = (ax >= az0) & (ax <= az1)\n",
    "        else:\n",
    "            ok = (ax >= az0) | (ax <= az1)\n",
    "        keep.append(ok)\n",
    "    gdf = gdf[np.array(keep, bool)]\n",
    "    if gdf.empty:\n",
    "        print(\"[warn] no segments within quadrant; writing unpruned result.\")\n",
    "        gdf = gpd.GeoDataFrame(geometry=lines, crs=gdf.crs)\n",
    "\n",
    "    gdf.to_file(streams_vec, driver=\"GPKG\")\n",
    "    print(\"→\", streams_vec)\n",
    "    return {\n",
    "        \"fa_tif\": fa, \"streams_bin\": streams_bin, \"streams_clean\": streams_thn, \"streams_vec\": streams_vec\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5189665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You already produced 03_dem_utm.tif earlier; if not, reproject your DEM to UTM zone 15N first.\n",
    "dem_utm = outdir / \"03_dem_utm.tif\"   # adjust if different\n",
    "res = extract_streams_ceniza_friendly(\n",
    "    dem_utm_tif=dem_utm, outdir=outdir,\n",
    "    summit_lon=-90.88, summit_lat=14.475,\n",
    "    fa_q=0.88, min_cells=40, min_len_m=1200, quadrant=(210,270)  # SW wedge\n",
    ")\n",
    "\n",
    "# Plot the result quickly with GeoPandas (UTM), or reproject to WGS84 for overlay:\n",
    "if res:\n",
    "    gdf = gpd.read_file(res[\"streams_vec\"])\n",
    "    gdf_ll = gdf.to_crs(4326)\n",
    "    ax = gdf_ll.plot(figsize=(8,8), linewidth=1, color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb9490b-b35a-4239-893a-634a87b73584",
   "metadata": {},
   "source": [
    "## 2. Load seismic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d040a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import Stream, read\n",
    "MSEED_DIR = DATA_DIR / \"ClipMSEED\"   \n",
    "st = Stream()\n",
    "for f in MSEED_DIR.glob('*.mseed'):\n",
    "    if 'HHZ' in str(f):\n",
    "        print(f)\n",
    "        tr = read(f)[0]\n",
    "        st.append(tr)\n",
    "print(st)\n",
    "st.plot();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7584f492",
   "metadata": {},
   "source": [
    "## 3. Remove instrument response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7ac062",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.detrend('linear')\n",
    "pre_filt = [0.5, 1.0, 80.0, 95.00]\n",
    "st.remove_response(pre_filt=pre_filt, inventory=INV, output='VEL')\n",
    "st.plot();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7434b9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "st_downsampled = st.copy()\n",
    "st_downsampled.decimate(factor=4)\n",
    "\n",
    "st_downsampled.spectrogram(dbscale=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df3f927",
   "metadata": {},
   "source": [
    "# Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f397ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_seconds = 10 \n",
    "beta = 1.25\n",
    "t_start_sec = 8000\n",
    "t_end_sec   = 9200\n",
    "event_st = st.copy()\n",
    "t0 = event_st[0].stats.starttime\n",
    "event_st.trim(starttime = t0+t_start_sec, endtime=t0+t_end_sec)\n",
    "peakf = 5.0\n",
    "Q = 30.0\n",
    "\n",
    "cfg = ASLConfig(\n",
    "    inventory=INV, \n",
    "    output_base=DATA_DIR / \"asl_results\", \n",
    "    gridobj=gridobj,\n",
    "    wave_kind='surface',\n",
    "    speed=beta,\n",
    "    peakf = peakf,\n",
    "    Q = Q,\n",
    "    window_seconds=window_seconds,\n",
    "    global_cache='/tmp',\n",
    "    station_correction_dataframe=None,\n",
    "    dist_mode=\"2d\", \n",
    "    misfit_engine=\"lin\",\n",
    "    min_stations=4,\n",
    "    sam_class=VSAM, \n",
    "    sam_metric=\"mean\",\n",
    "    debug=True,\n",
    ")\n",
    "cfg.build()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eabd48b",
   "metadata": {},
   "source": [
    "# Locate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78206e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mseed_file = '/tmp/jacob_event.mseed'\n",
    "event_st.write(mseed_file, format='MSEED')\n",
    "result = run_single_event(\n",
    "    mseed_file=mseed_file,\n",
    "    cfg=cfg,\n",
    "    station_gains_df=None,\n",
    "    switch_event_ctag = True,\n",
    "    topo_kw=topo_kw,\n",
    "    mseed_units='m/s', # default units for miniseed files being used - probably \"Counts\" or \"m/s\"        \n",
    "    reduce_time=True,\n",
    "    refine_sector=False,\n",
    "    debug=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flovopy_plus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
