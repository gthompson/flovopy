{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6ce9277",
   "metadata": {},
   "source": [
    "# 1. Set up parameters for ASL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94679f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from obspy import read_inventory\n",
    "from importlib import reload\n",
    "from flovopy.asl.wrappers import run_single_event, find_event_files, run_all_events\n",
    "from flovopy.core.mvo import dome_location, REGION_DEFAULT\n",
    "from flovopy.processing.sam import VSAM, DSAM \n",
    "from flovopy.asl.config import ASLConfig\n",
    "# -------------------------- Config --------------------------\n",
    "# directories\n",
    "HOME = Path.home()\n",
    "PROJECTDIR      = HOME / \"Dropbox\" / \"BRIEFCASE\" / \"SSADenver\"\n",
    "LOCALPROJECTDIR = HOME / \"work\" / \"PROJECTS\" / \"SSADenver_local\"\n",
    "OUTPUT_DIR      = LOCALPROJECTDIR / \"ASL_RESULTS\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "INPUT_DIR       = PROJECTDIR / \"ASL_inputs\" / \"biggest_pdc_events\"\n",
    "GLOBAL_CACHE    = PROJECTDIR / \"asl_global_cache\"\n",
    "METADATA_DIR    = PROJECTDIR / \"metadata\" \n",
    "STATION_CORRECTIONS_DIR = PROJECTDIR / \"station_correction_analysis\"\n",
    "\n",
    "# master files\n",
    "INVENTORY_XML   = METADATA_DIR / \"MV_Seismic_and_GPS_stations.xml\"\n",
    "DEM_DEFAULT     = METADATA_DIR / \"MONTSERRAT_DEM_WGS84_MASTER.tif\"\n",
    "GRIDFILE_DEFAULT= METADATA_DIR / \"MASTER_GRID_MONTSERRAT.pkl\"\n",
    "\n",
    "# parameters for envelopes and cross-correlation\n",
    "SMOOTH_SECONDS  = 1.0\n",
    "MAX_LAG_SECONDS = 8.0\n",
    "MIN_XCORR       = 0.5\n",
    "\n",
    "# other parameters\n",
    "DIST_MODE = \"3d\" # or 2d. will essentially squash Montserrat topography and stations onto a sea-level plane, ignored elevation data, e.g. for computing distances\n",
    "\n",
    "# Inventory of Montserrat stations\n",
    "from obspy import read_inventory\n",
    "INV     = read_inventory(INVENTORY_XML)\n",
    "print(f\"[INV] Networks: {len(INV)}  Stations: {sum(len(n) for n in INV)}  Channels: {sum(len(sta) for net in INV for sta in net)}\")\n",
    "\n",
    "# Montserrat station corrections estimated from regionals\n",
    "station_corrections_csv = STATION_CORRECTIONS_DIR / \"station_gains_intervals.csv\"\n",
    "annual_station_corrections_csv = STATION_CORRECTIONS_DIR / \"station_gains_intervals_by_year.csv\"\n",
    "station_corrections_df = pd.read_csv(station_corrections_csv)\n",
    "annual_station_corrections_df = pd.read_csv(annual_station_corrections_csv)\n",
    "\n",
    "# Montserrat pre-defined Grid (from 02 tutorial)\n",
    "from flovopy.asl.grid import Grid\n",
    "gridobj = Grid.load(GRIDFILE_DEFAULT)\n",
    "print(gridobj)\n",
    "\n",
    "\n",
    "# Montserrat constants\n",
    "from flovopy.core.mvo import dome_location, REGION_DEFAULT\n",
    "print(\"Dome (assumed source) =\", dome_location)\n",
    "\n",
    "# events and wrappers\n",
    "event_files = list(find_event_files(INPUT_DIR))\n",
    "eventcsvfile = Path(OUTPUT_DIR) / \"mseed_files.csv\"\n",
    "if not eventcsvfile.is_file():\n",
    "    rows = [{\"num\": num, \"f\": str(f)} for num, f in enumerate(event_files)]\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(eventcsvfile, index=False)\n",
    "best_file_nums  = [35, 36, 40, 52, 82, 83, 84, 116, 310, 338]\n",
    "best_event_files = [event_files[i] for i in best_file_nums]\n",
    "print(f'Best miniseed files are: {best_event_files}')\n",
    "REFINE_SECTOR = False   # enable triangular dome-to-sea refinement\n",
    "\n",
    "# Parameters to pass for making pygmt topo maps\n",
    "topo_kw = {\n",
    "    \"inv\": INV,\n",
    "    \"add_labels\": True,\n",
    "    \"cmap\": \"gray\",\n",
    "    \"region\": REGION_DEFAULT,\n",
    "    \"dem_tif\": DEM_DEFAULT,  # basemap shading from your GeoTIFF - but does not actually seem to use this unless topo_color=True and cmap=None\n",
    "    \"frame\": True,\n",
    "    \"dome_location\": dome_location,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc2fe03",
   "metadata": {},
   "source": [
    "# Build a baseline configuration\n",
    "This is inherited by various downstream functions\n",
    "This describes the physical parameters, the station metadata, the grid, the misfit algorithm, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed3982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG=False\n",
    "baseline_cfg = ASLConfig(\n",
    "    inventory=INV,\n",
    "    output_base=OUTPUT_DIR,\n",
    "    gridobj=gridobj,\n",
    "    global_cache=GLOBAL_CACHE,\n",
    "    station_correction_dataframe=station_corrections_df,\n",
    "    wave_kind=\"surface\",\n",
    "    speed=1.5,\n",
    "    Q=23, \n",
    "    peakf=2.0,\n",
    "    dist_mode=\"3d\", \n",
    "    misfit_engine=\"r2\",\n",
    "    window_seconds=5.0,\n",
    "    min_stations=5,\n",
    "    sam_class=VSAM, \n",
    "    sam_metric=\"mean\",\n",
    "    debug=DEBUG,\n",
    ")\n",
    "baseline_cfg.build()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd2c7cd",
   "metadata": {},
   "source": [
    "# Run events (one event=one miniseed file) with this baseline configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c53684",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = []\n",
    "REFINE_SECTOR=False\n",
    "for i, ev in zip(best_file_nums, best_event_files):\n",
    "    print(f\"[{i}/{len(event_files)}] {ev}\")\n",
    "    result = run_single_event(\n",
    "        mseed_file=str(ev),\n",
    "        cfg=baseline_cfg,\n",
    "        refine_sector=REFINE_SECTOR,\n",
    "        station_gains_df=None,\n",
    "        switch_event_ctag = True,\n",
    "        topo_kw=topo_kw,\n",
    "        mseed_units='m/s', # default units for miniseed files being used - probably \"Counts\" or \"m/s\"        \n",
    "        reduce_time=True,\n",
    "        debug=DEBUG,\n",
    "    )\n",
    "    summaries.append(result)\n",
    "\n",
    "# Summarize\n",
    "df = pd.DataFrame(summaries)\n",
    "display(df)\n",
    "\n",
    "summary_csv = Path(OUTPUT_DIR) / f\"{baseline_cfg.tag()}__summary.csv\"\n",
    "df.to_csv(summary_csv, index=False)\n",
    "print(f\"Summary saved to: {summary_csv}\")\n",
    "\n",
    "if not df.empty:\n",
    "    n_ok = int((~df.get(\"error\").notna()).sum()) if \"error\" in df.columns else len(df)\n",
    "    print(f\"Success: {n_ok}/{len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07410026",
   "metadata": {},
   "source": [
    "# Easily create new configurations that change 1 or 2 parameters\n",
    "Here we create 18 new configurations, each is an entry in the changes dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1063c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flovopy.asl.compare_runs import tweak_config, compare_runs\n",
    "landgridobj = Grid.load(GLOBAL_CACHE / \"land\" / \"Grid_9c2fd59b.pkl\")\n",
    "\n",
    "variants = tweak_config(\n",
    "    baseline_cfg,\n",
    "    changes=[\n",
    "        {\"Q\": 10},                                      # decrease Q from 23 to 10\n",
    "        {\"Q\": 100},                                     # increase Q from 23 to 100\n",
    "        {\"speed\": 0.5},                                 # decrease wave speed from 1.5 km/s to 0.5 km/s\n",
    "        {\"speed\": 2.5},                                 # increase wave speed from 1.5 km/s to 2.5 km/s\n",
    "        {\"peakf\": 8.0},                                 # increae peakf from 2.0 Hz to 8.0 Hz\n",
    "        {\"dist_mode\": \"2d\"},                            # change from 3D to 2D: ignore terrain & ignore station elevations\n",
    "        {\"station_correction_dataframe\": None},         # turn off station corrections\n",
    "        {\"gridobj\":landgridobj},                        # try a grid that allows whole Southern end of island, not just dome & ravines\n",
    "        {\"misfit_engine\": \"l2\"},                        # change the misfit function from r2 to l2\n",
    "        {\"misfit_engine\": \"lin\"},                       # change the misfit function from r2 to lin\n",
    "        {\"window_seconds\": 1.0},                        # decrease the moving window length from 5-s to 1-s\n",
    "        {\"sam_class\": DSAM},                            # switch from VELOCITY Seismic Amplitude Measurement (VSAM) to DISPLACEMENT Seismic Amplitude Measurement (DSAM)\n",
    "        {\"sam_metric\": \"median\"},                       # switch from MEAN of each 5-s moving time window, to MEDIAN\n",
    "        {\"sam_metric\": \"rms\"},                          # switch from MEAN of each 5-s moving time window, to RMS\n",
    "        {\"sam_metric\": \"max\"},                          # switch from MEAN of each 5-s moving time window, to MAX\n",
    "        {\"sam_metric\": \"LP\"},                           # switch from MEAN in 0.5-18.0 Hz band to mean in LP band (0.5-4.0 Hz)\n",
    "        {\"sam_metric\": \"VT\"},                           # switch from MEAN in 0.5-18.0 Hz band to mean in VT band (4.0-18.0 Hz)\n",
    "        {\"wave_kind\": \"body\", \"speed\": 2.5},            # change multiple params: surface->body waves, wave speed 1.5->3.0 km/s - THIS IS A REFERENCE TO COMPARE SURFACE WAVES AND BODY WAVES\n",
    "    ],\n",
    ")\n",
    "print(variants)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b863f424",
   "metadata": {},
   "source": [
    "# Run pairs: variant vs baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d0e325",
   "metadata": {},
   "outputs": [],
   "source": [
    "scored, summary, win_counts = compare_runs(\n",
    "    baseline_cfg,\n",
    "    events=best_event_files,\n",
    "    variants=variants,\n",
    "    run_single_event=run_single_event,\n",
    "    refine_sector=False,\n",
    "    topo_kw=topo_kw,\n",
    "    run_if_missing_baseline=True,\n",
    "    run_if_missing_variants=True,\n",
    "    # the following numbers should add up to 1.0. if truly just want to see difference RELATIVE to baseline, set w_sep=1.0, and others to 0.0. for ABSOLUTE quality check, set w_sep to 0.0\n",
    "    w_sep=0.5, # set this high to penalize large location difference from the baseline config\n",
    "    w_misfit=0.2, # set this high to punish high misfits\n",
    "    w_azgap=0.1, # punish larger azimuthal gaps\n",
    "    w_conn=0.1, # reward more connectedness\n",
    "    w_rough=0.1, # reward less roughness / more straightness\n",
    ")\n",
    "\n",
    "# 4) Inspect/save\n",
    "if scored is not None:\n",
    "    display(summary)\n",
    "    display(win_counts)\n",
    "    summary.to_csv(OUTPUT_DIR / \"pairwise_summary_surface.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b75c0a5",
   "metadata": {},
   "source": [
    "## baseline-free absolute scoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b0ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flovopy.asl.compare_runs import build_intrinsic_table, add_baseline_free_scores, summarize_absolute_runs, per_event_winner_abs, crawl_intrinsic_runs\n",
    "\n",
    "'''\n",
    "# Option A: ensure CSVs by (re)running baseline + variants you care about\n",
    "abs_tbl = build_intrinsic_table(\n",
    "    baseline_cfg,\n",
    "    events=best_event_files,\n",
    "    variants=variants,\n",
    "    run_single_event=run_single_event,\n",
    "    refine_sector=False, topo_kw=topo_kw,\n",
    "    run_if_missing_baseline=False,     # set True if you want it to run\n",
    "    run_if_missing_variants=False,     # set True to auto-run variants\n",
    ")\n",
    "'''\n",
    "\n",
    "# Option B: OR just crawl everything that already exists under OUTPUT_DIR\n",
    "abs_tbl = crawl_intrinsic_runs(OUTPUT_DIR)\n",
    "weights = {\n",
    "    \"mean_misfit\":     1.0,   # lower better\n",
    "    \"mean_azgap\":      0.1,   # lower better\n",
    "    \"roughness_ratio\": 0.1,   # lower better\n",
    "    \"connectedness\":  -0.3,   # higher better (negative weight)\n",
    "    \"valid_frac\":     -0.2,   # higher better (negative weight)\n",
    "}\n",
    "abs_scored = add_baseline_free_scores(abs_tbl, weights=weights)\n",
    "\n",
    "abs_summary = summarize_absolute_runs(abs_scored)\n",
    "winners_abs, win_counts_abs = per_event_winner_abs(abs_scored)\n",
    "\n",
    "display(abs_summary)\n",
    "display(win_counts_abs)\n",
    "\n",
    "abs_summary.to_csv(OUTPUT_DIR / \"absolute_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facaa266",
   "metadata": {},
   "source": [
    "# Now let's try to run a suite of body wave configurations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0efb298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new baseline configuration - this time for body waves\n",
    "baseline_cfg = ASLConfig(\n",
    "    inventory=INV,\n",
    "    output_base=OUTPUT_DIR,\n",
    "    gridobj=gridobj,\n",
    "    global_cache=GLOBAL_CACHE,\n",
    "    station_correction_dataframe=station_corrections_df,\n",
    "    wave_kind=\"body\",\n",
    "    speed=2.5,\n",
    "    Q=23, \n",
    "    peakf=2.0,\n",
    "    dist_mode=\"3d\", \n",
    "    misfit_engine=\"r2\",\n",
    "    window_seconds=5.0,\n",
    "    min_stations=5,\n",
    "    sam_class=VSAM, \n",
    "    sam_metric=\"mean\",\n",
    "    debug=DEBUG,\n",
    ")\n",
    "baseline_cfg.build()\n",
    "\n",
    "# Easily create new configurations - 18 new ones\n",
    "variants = tweak_config(\n",
    "    baseline_cfg,\n",
    "    changes=[\n",
    "        {\"Q\": 10},                                      # decrease Q from 23 to 10\n",
    "        {\"Q\": 100},                                     # increase Q from 23 to 100\n",
    "        {\"speed\": 1.5},                                 # decrease wave speed from 2.5 km/s to 1.5 km/s\n",
    "        {\"speed\": 4.0},                                 # increase wave speed from 2.5 km/s to 4.0 km/s\n",
    "        {\"peakf\": 8.0},                                 # increae peakf from 2.0 Hz to 8.0 Hz\n",
    "        {\"dist_mode\": \"2d\"},                            # change from 3D to 2D: ignore terrain & ignore station elevations\n",
    "        {\"station_correction_dataframe\": None},         # turn off station corrections\n",
    "        {\"gridobj\":landgridobj},                        # try a grid that allows whole Southern end of island, not just dome & ravines\n",
    "        {\"misfit_engine\": \"l2\"},                        # change the misfit function from r2 to l2\n",
    "        {\"misfit_engine\": \"lin\"},                       # change the misfit function from r2 to lin\n",
    "        {\"window_seconds\": 1.0},                        # decrease the moving window length from 5-s to 1-s\n",
    "        {\"sam_class\": DSAM},                            # switch from VELOCITY Seismic Amplitude Measurement (VSAM) to DISPLACEMENT Seismic Amplitude Measurement (DSAM)\n",
    "        {\"sam_metric\": \"median\"},                       # switch from MEAN of each 5-s moving time window, to MEDIAN\n",
    "        {\"sam_metric\": \"rms\"},                          # switch from MEAN of each 5-s moving time window, to RMS\n",
    "        {\"sam_metric\": \"max\"},                          # switch from MEAN of each 5-s moving time window, to MAX\n",
    "        {\"sam_metric\": \"LP\"},                           # switch from MEAN in 0.5-18.0 Hz band to mean in LP band (0.5-4.0 Hz)\n",
    "        {\"sam_metric\": \"VT\"},                           # switch from MEAN in 0.5-18.0 Hz band to mean in VT band (4.0-18.0 Hz)\n",
    "        {\"wave_kind\": \"surface\", \"speed\": 1.0},         # change multiple params: surface->body waves, wave speed 1.5->3.0 km/s - THIS IS A REFERENCE TO COMPARE SURFACE WAVES AND BODY WAVES\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Run pairs - variant versus baseline\n",
    "scored, summary, win_counts = compare_runs(\n",
    "    baseline_cfg,\n",
    "    events=best_event_files,\n",
    "    variants=variants,\n",
    "    run_single_event=run_single_event,\n",
    "    refine_sector=False,\n",
    "    topo_kw=topo_kw,\n",
    "    run_if_missing_baseline=True,\n",
    "    run_if_missing_variants=True,\n",
    "    # the following numbers should add up to 1.0. if truly just want to see difference RELATIVE to baseline, set w_sep=1.0, and others to 0.0. for ABSOLUTE quality check, set w_sep to 0.0\n",
    "    w_sep=0.5, # set this high to penalize large location difference from the baseline config\n",
    "    w_misfit=0.2, # set this high to punish high misfits\n",
    "    w_azgap=0.1, # punish larger azimuthal gaps\n",
    "    w_conn=0.1, # reward more connectedness\n",
    "    w_rough=0.1, # reward less roughness / more straightness\n",
    ")\n",
    "\n",
    "if scored is not None:\n",
    "    display(summary)\n",
    "    display(win_counts)\n",
    "    summary.to_csv(OUTPUT_DIR / \"pairwise_summary_surface.csv\", index=False)\n",
    "\n",
    "\n",
    "# baseline-free absolute scoring\n",
    "abs_tbl = crawl_intrinsic_runs(OUTPUT_DIR)\n",
    "weights = {\n",
    "    \"mean_misfit\":     1.0,   # lower better\n",
    "    \"mean_azgap\":      0.1,   # lower better\n",
    "    \"roughness_ratio\": 0.1,   # lower better\n",
    "    \"connectedness\":  -0.3,   # higher better (negative weight)\n",
    "    \"valid_frac\":     -0.2,   # higher better (negative weight)\n",
    "}\n",
    "abs_scored = add_baseline_free_scores(abs_tbl, weights=weights)\n",
    "\n",
    "abs_summary = summarize_absolute_runs(abs_scored)\n",
    "winners_abs, win_counts_abs = per_event_winner_abs(abs_scored)\n",
    "\n",
    "display(abs_summary)\n",
    "display(win_counts_abs)\n",
    "\n",
    "abs_summary.to_csv(OUTPUT_DIR / \"absolute_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2000dcae",
   "metadata": {},
   "source": [
    "# Run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8960cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fred import bloggs\n",
    "from flovopy.asl.compare_runs import (\n",
    "    tweak_config, compare_runs,\n",
    "    load_all_event_comparisons, summarize_variants, per_event_winner\n",
    ")\n",
    "\n",
    "REFINE_SECTOR = False\n",
    "landgridobj = Grid.load(GLOBAL_CACHE / \"land\" / \"Grid_9c2fd59b.pkl\")\n",
    "\n",
    "# 2) Variants\n",
    "variants = tweak_config(\n",
    "    baseline_cfg,\n",
    "    changes=[\n",
    "        {\"Q\": 100},\n",
    "        {\"speed\": 3.0},\n",
    "        {\"dist_mode\": \"2d\"},\n",
    "        {\"station_correction_dataframe\": None},        # turn off stacorr\n",
    "        {\"wave_kind\": \"body\", \"speed\": 3.2, \"Q\": 80},  # change multiple params\n",
    "    ],\n",
    ")\n",
    "'''\n",
    "# generate a sweep\n",
    "variants = tweak_config(\n",
    "    baseline_cfg,\n",
    "    axes={\n",
    "        \"speed\": [1.5, 3.0],\n",
    "        \"Q\": [23, 100],\n",
    "    },\n",
    "    changes=[{\"dist_mode\": \"2d\"}],  # also try all of the above in 2D\n",
    ")\n",
    "\n",
    "# support previous version\n",
    "variants = tweak_config(\n",
    "    baseline_cfg,\n",
    "    landgridobj=landgridobj,\n",
    "    annual_station_corrections_df=annual_station_corrections_df,\n",
    ")\n",
    "'''\n",
    "\n",
    "# 3) Run\n",
    "scored, summary, win_counts = compare_runs(\n",
    "    baseline_cfg,\n",
    "    events=best_event_files,\n",
    "    variants=variants,\n",
    "    run_single_event=run_single_event,\n",
    "    refine_sector=False,\n",
    "    topo_kw=topo_kw,\n",
    "    run_if_missing_baseline=True,\n",
    "    run_if_missing_variants=True,\n",
    "    w_sep=1.0, w_misfit=0.5, w_azgap=0.1,\n",
    ")\n",
    "\n",
    "# 4) Inspect/save\n",
    "if scored is not None:\n",
    "    display(summary)\n",
    "    display(win_counts)\n",
    "    summary.to_csv(OUTPUT_DIR / \"pairwise_summary_surface.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffad9ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d57d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ✅ use the new module:\n",
    "from flovopy.asl.compare_runs2 import (\n",
    "    cfg_variants_from,\n",
    "    compare_runs,            # orchestrator\n",
    "    load_all_event_comparisons,  # optional if you want to re-load later\n",
    "    add_composite_score,         # optional\n",
    "    summarize_variants,          # optional\n",
    "    per_event_winner,            # optional\n",
    ")\n",
    "\n",
    "# --- Build baseline & variants ---\n",
    "landgridobj = Grid.load(GLOBAL_CACHE / \"land\" / \"Grid_9c2fd59b.pkl\")\n",
    "baseline_cfg = ASLConfig(\n",
    "    inventory=INV,\n",
    "    output_base=OUTPUT_DIR,\n",
    "    gridobj=gridobj,\n",
    "    global_cache=GLOBAL_CACHE,\n",
    "    station_correction_dataframe=station_corrections_df,\n",
    "    wave_kind=\"surface\",\n",
    "    speed=1.5,\n",
    "    Q=23,\n",
    "    peakf=2.0,\n",
    "    dist_mode=\"3d\",\n",
    "    misfit_engine=\"r2\",\n",
    "    window_seconds=5.0,\n",
    "    min_stations=5,\n",
    "    sam_class=VSAM,\n",
    "    sam_metric=\"mean\",\n",
    "    debug=False,\n",
    ").build()\n",
    "\n",
    "variants = cfg_variants_from(\n",
    "    baseline_cfg,\n",
    "    landgridobj=landgridobj,\n",
    "    annual_station_corrections_df=annual_station_corrections_df,\n",
    ")\n",
    "\n",
    "# --- Run comparisons (auto-run baseline & variants if missing) ---\n",
    "scored, summary, win_counts = compare_runs(\n",
    "    baseline_cfg,\n",
    "    events=best_event_files,            # iterable of mseed paths\n",
    "    variants=variants,\n",
    "    run_single_event=run_single_event,  # your existing function\n",
    "    refine_sector=False,\n",
    "    topo_kw=topo_kw,\n",
    "    run_if_missing_baseline=True,\n",
    "    run_if_missing_variants=True,       # flip to False if you want variants manual\n",
    "    w_sep=1.0, w_misfit=0.5, w_azgap=0.1,\n",
    ")\n",
    "\n",
    "# --- Show results ---\n",
    "if scored is not None:\n",
    "    display(summary)\n",
    "    display(win_counts)\n",
    "summary.to_csv(OUTPUT_DIR / \"pairwise_summary_surface.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd8621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flovopy.asl.compare_runs import compare_runs, build_intrinsic_table, add_baseline_free_scores, summarize_absolute_runs, per_event_winner_abs\n",
    "\n",
    "# 1) (optional) still run pairwise comparisons\n",
    "'''\n",
    "scored_pairwise, summary_pairwise, win_counts_pairwise = compare_runs(\n",
    "    baseline_cfg,\n",
    "    events=best_event_files,\n",
    "    variants=variants,\n",
    "    run_single_event=run_single_event,\n",
    "    refine_sector=False,\n",
    "    topo_kw=topo_kw,\n",
    "    run_if_missing_baseline=True,\n",
    "    run_if_missing_variants=True,\n",
    ")\n",
    "'''\n",
    "def per_event_winner_abs(df_abs_scored: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Pick the min score_abs per event_id using label indexing (safe).\n",
    "    Skips events with all-NaN score_abs.\n",
    "    \"\"\"\n",
    "    if df_abs_scored is None or df_abs_scored.empty or \"score_abs\" not in df_abs_scored.columns:\n",
    "        return (pd.DataFrame(columns=[\"event_id\",\"tag\",\"score_abs\"]),\n",
    "                pd.DataFrame(columns=[\"tag\",\"wins\"]))\n",
    "\n",
    "    d = df_abs_scored[np.isfinite(df_abs_scored[\"score_abs\"])].copy()\n",
    "    if d.empty:\n",
    "        return (pd.DataFrame(columns=[\"event_id\",\"tag\",\"score_abs\"]),\n",
    "                pd.DataFrame(columns=[\"tag\",\"wins\"]))\n",
    "\n",
    "    idx = d.groupby(\"event_id\")[\"score_abs\"].idxmin().dropna()\n",
    "    winners = d.loc[idx, [\"event_id\",\"tag\",\"score_abs\"]].reset_index(drop=True)  # <-- loc, not iloc\n",
    "    win_counts = (winners[\"tag\"]\n",
    "                  .value_counts()\n",
    "                  .rename_axis(\"tag\")\n",
    "                  .reset_index(name=\"wins\")\n",
    "                  .sort_values(\"wins\", ascending=False))\n",
    "    return winners, win_counts\n",
    "\n",
    "\n",
    "# 2) Build absolute (baseline-free) table and scores\n",
    "abs_tbl = build_intrinsic_table(\n",
    "    baseline_cfg,\n",
    "    events=best_event_files,\n",
    "    variants=variants,\n",
    "    run_single_event=run_single_event,\n",
    "    refine_sector=False,\n",
    "    topo_kw=topo_kw,\n",
    "    run_if_missing_baseline=False,   # set True if you want to autorun here too\n",
    "    run_if_missing_variants=False,\n",
    ")\n",
    "\n",
    "abs_scored = add_baseline_free_scores(abs_tbl)  # you can pass custom weights=...\n",
    "abs_summary = summarize_absolute_runs(abs_scored)\n",
    "winners_abs, win_counts_abs = per_event_winner_abs(abs_scored)\n",
    "\n",
    "abs_summary.to_csv(OUTPUT_DIR / \"abs_summary.csv\", index=False)\n",
    "win_counts_abs.to_csv(OUTPUT_DIR / \"win_counts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c5d40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flovopy.asl.compare_runs import crawl_intrinsic_runs\n",
    "abs_tbl = crawl_intrinsic_runs(OUTPUT_DIR)\n",
    "abs_scored  = add_baseline_free_scores(abs_tbl)\n",
    "abs_summary = summarize_absolute_runs(abs_scored)\n",
    "winners_abs, win_counts_abs = per_event_winner_abs(abs_scored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198a0459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run ASL per event (cell 6) ---\n",
    "'''\n",
    "from typing import List, Dict, Any\n",
    "summaries: List[Dict[str, Any]] = []\n",
    "\n",
    "for i, ev in zip(best_file_nums, best_event_files):\n",
    "    print(f\"[{i}/{len(event_files)}] {ev}\")\n",
    "    result = run_single_event(\n",
    "        mseed_file=str(ev),\n",
    "        cfg=cfg,\n",
    "        refine_sector=REFINE_SECTOR,\n",
    "        station_gains_df=None,\n",
    "        topo_kw=topo_kw,\n",
    "        debug=True,\n",
    "    )\n",
    "    summaries.append(result)\n",
    "    break\n",
    "\n",
    "# Summarize\n",
    "df = pd.DataFrame(summaries)\n",
    "display(df)\n",
    "\n",
    "summary_csv = Path(OUTPUT_DIR) / f\"{cfg.tag()}__summary.csv\"\n",
    "df.to_csv(summary_csv, index=False)\n",
    "print(f\"Summary saved to: {summary_csv}\")\n",
    "\n",
    "if not df.empty:\n",
    "    n_ok = int((~df.get(\"error\").notna()).sum()) if \"error\" in df.columns else len(df)\n",
    "    print(f\"Success: {n_ok}/{len(df)}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39632ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_all_event_comparisons(root: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Crawl event folders under `root` and stack `pairwise_run_comparisons.csv`.\n",
    "    Returns a tidy DF with event_id inferred from folder name.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for csv in root.rglob(\"pairwise_run_comparisons.csv\"):\n",
    "        try:\n",
    "            df = pd.read_csv(csv)\n",
    "            df[\"event_id\"] = csv.parent.name            # the event folder name\n",
    "            rows.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"[skip] {csv}: {e}\")\n",
    "    if not rows:\n",
    "        return pd.DataFrame()\n",
    "    out = pd.concat(rows, ignore_index=True)\n",
    "    # normalize label text to a short key\n",
    "    out[\"variant\"] = out[\"label\"].astype(str)\n",
    "    # guard presence of expected columns\n",
    "    for c in [\"mean_sep_km\",\"delta_misfit_B_minus_A\",\"delta_azgap_B_minus_A\"]:\n",
    "        if c not in out.columns: out[c] = np.nan\n",
    "    return out\n",
    "\n",
    "def add_composite_score(df: pd.DataFrame,\n",
    "                        w_sep=1.0, w_misfit=0.5, w_azgap=0.1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Lower is better. Negative deltas are good if they reduce misfit/azgap.\n",
    "    \"\"\"\n",
    "    d = df.copy()\n",
    "    # z-score each metric for comparability (event-wise optional)\n",
    "    # here: global z-scores; switch to per-event z if events differ strongly in scale\n",
    "    for col in [\"mean_sep_km\",\"delta_misfit_B_minus_A\",\"delta_azgap_B_minus_A\"]:\n",
    "        x = d[col].to_numpy(dtype=float)\n",
    "        mu, sd = np.nanmean(x), np.nanstd(x) if np.nanstd(x)>0 else 1.0\n",
    "        d[col+\"_z\"] = (x - mu)/sd\n",
    "    d[\"score\"] = (\n",
    "        w_sep    * d[\"mean_sep_km_z\"] +\n",
    "        w_misfit * d[\"delta_misfit_B_minus_A_z\"] +\n",
    "        w_azgap  * d[\"delta_azgap_B_minus_A_z\"]\n",
    "    )\n",
    "    return d\n",
    "\n",
    "def summarize_variants(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    One line per variant: mean±SE of core metrics and composite score,\n",
    "    plus 'wins' (how often variant beats baseline the most for an event).\n",
    "    \"\"\"\n",
    "    g = df.groupby(\"variant\", dropna=False)\n",
    "    agg = g.agg(\n",
    "        n_events          = (\"event_id\", \"nunique\"),\n",
    "        n_rows            = (\"event_id\", \"size\"),\n",
    "        mean_sep_km_mean  = (\"mean_sep_km\", \"mean\"),\n",
    "        mean_sep_km_med   = (\"mean_sep_km\", \"median\"),\n",
    "        mean_sep_km_se    = (\"mean_sep_km\", lambda x: np.nanstd(x)/np.sqrt(max(1,(x.notna().sum())))),\n",
    "        dmisfit_mean      = (\"delta_misfit_B_minus_A\", \"mean\"),\n",
    "        dmisfit_med       = (\"delta_misfit_B_minus_A\", \"median\"),\n",
    "        dazgap_mean       = (\"delta_azgap_B_minus_A\", \"mean\"),\n",
    "        score_mean        = (\"score\", \"mean\"),\n",
    "        score_med         = (\"score\", \"median\"),\n",
    "    ).reset_index().sort_values(\"score_mean\")\n",
    "    return agg\n",
    "\n",
    "def per_event_winner(df_scored: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each event, pick the variant with the lowest composite score.\n",
    "    \"\"\"\n",
    "    # keep only the best per (event_id)\n",
    "    idx = df_scored.groupby(\"event_id\")[\"score\"].idxmin()\n",
    "    winners = df_scored.loc[idx, [\"event_id\",\"variant\",\"score\"]]\n",
    "    win_counts = winners.groupby(\"variant\").size().rename(\"wins\").reset_index()\n",
    "    return winners, win_counts.sort_values(\"wins\", ascending=False)\n",
    "\n",
    "# --- run it ---\n",
    "ROOT = OUTPUT_DIR  # your existing OUTDIR base\n",
    "allcmp = load_all_event_comparisons(ROOT)\n",
    "print(f\"stacked rows: {len(allcmp)}, events: {allcmp['event_id'].nunique()}\")\n",
    "\n",
    "scored = add_composite_score(allcmp, w_sep=1.0, w_misfit=0.5, w_azgap=0.1)\n",
    "summary = summarize_variants(scored)\n",
    "winners, win_counts = per_event_winner(scored)\n",
    "\n",
    "# quick looks\n",
    "display(summary.head(10))\n",
    "display(win_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc13f72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_tbl    = build_intrinsic_table(baseline_cfg, events=best_event_files, variants=variants,\n",
    "                                   run_single_event=run_single_event, refine_sector=False,\n",
    "                                   topo_kw=topo_kw, run_if_missing_baseline=True,\n",
    "                                   run_if_missing_variants=True)\n",
    "\n",
    "abs_scored = add_baseline_free_scores(abs_tbl)  # or pass custom weights=\n",
    "abs_summary = summarize_absolute_runs(abs_scored)\n",
    "winners_abs, win_counts_abs = per_event_winner_abs(abs_scored)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a47df7",
   "metadata": {},
   "source": [
    "# Run all events efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552236da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(INPUT_DIR)\n",
    "print(cfg)\n",
    "print(topo_kw)\n",
    "print(REFINE_SECTOR)\n",
    "'''\n",
    "run_all_events(\n",
    "    input_dir=INPUT_DIR,\n",
    "    station_gains_df = None,\n",
    "    cfg=cfg,\n",
    "    refine_sector=REFINE_SECTOR,\n",
    "    topo_kw=topo_kw,\n",
    "    debug=True,\n",
    "    max_events=999999,\n",
    "    use_multiprocessing=True,\n",
    "    workers=4,\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613e3b64",
   "metadata": {},
   "source": [
    "# Run Monte Carlo sweep of parameters for 1 event\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13b73fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from flovopy.asl.wrappers2 import run_event_monte_carlo\n",
    "from flovopy.processing.sam import VSAM, DSAM\n",
    "'''\n",
    "# Simple 6-draw sweep (replace with your own priors/sequences)\n",
    "configs = ASLConfig.generate_config_list(\n",
    "    inventory=None,\n",
    "    output_base=None,\n",
    "    gridobj=None,\n",
    "    global_cache=None,      \n",
    "    wave_kinds=(\"surface\",\"body\"),\n",
    "    station_corr_tables=(station_corrections_df), #annual_station_corrections_df),\n",
    "    speeds=(1.0, 3.0),\n",
    "    Qs=(23, 1000),\n",
    "    dist_modes=(\"3d\",), # 2d needs a different grid and different distance and amplitude corrections\n",
    "    misfit_engines=(\"l2\",\"r2\", \"lin\"),\n",
    "    peakfs=(2.0, 8.0),\n",
    "    window_seconds = 5.0, # change to be a tuple 10.0) not implemented yet\n",
    "    min_stations = 5,\n",
    "    sam_class = (VSAM), #, DSAM), # not implemented yet\n",
    "    sam_metric = (\"mean\"),# \"median\", \"rms\", \"VT\", \"LP\"), # this doesn't seem to be implemented yet\n",
    "    # context can be set later; set here if you like:\n",
    "    debug=False,\n",
    ")\n",
    "\n",
    "configs = ASLConfig.generate_config_list(\n",
    "    inventory=None,\n",
    "    output_base=None,\n",
    "    gridobj=None,\n",
    "    global_cache=None,      \n",
    "    wave_kinds=(\"surface\",),\n",
    "    station_corr_tables=(station_corrections_df), #annual_station_corrections_df),\n",
    "    speeds=(1.0, 3.0),\n",
    "    Qs=(23, 1000),\n",
    "    dist_modes=(\"3d\",), # 2d needs a different grid and different distance and amplitude corrections\n",
    "    misfit_engines=(\"l2\"),\n",
    "    peakfs=(8.0),\n",
    "    window_seconds = 5.0, # change to be a tuple 10.0) not implemented yet\n",
    "    min_stations = 5,\n",
    "    sam_class = (VSAM), #, DSAM), # not implemented yet\n",
    "    sam_metric = (\"mean\"),# \"median\", \"rms\", \"VT\", \"LP\"), # this doesn't seem to be implemented yet\n",
    "    # context can be set later; set here if you like:\n",
    "    debug=False,\n",
    ")\n",
    "\n",
    "\n",
    "configs = ASLConfig.generate_config_list(    \n",
    "    inventory=INV,\n",
    "    output_base=str(OUTPUT_DIR),\n",
    "    gridobj=gridobj,\n",
    "    global_cache=GLOBAL_CACHE,\n",
    ") \n",
    "\n",
    "print(len(configs))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21faaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Shared run context\n",
    "mseed_file   = event_files[116]\n",
    "'''\n",
    "results = run_event_monte_carlo(\n",
    "    mseed_file=mseed_file,\n",
    "    configs=configs,\n",
    "    inventory=INV,\n",
    "    output_base=str(OUTPUT_DIR),\n",
    "    gridobj=gridobj,\n",
    "    topo_kw=topo_kw,\n",
    "    station_gains_df=None,\n",
    "    parallel=False,\n",
    "    max_workers=1,\n",
    "    global_cache=GLOBAL_CACHE,\n",
    "    debug=True,\n",
    ")\n",
    "\n",
    "# Inspect or summarize results as needed\n",
    "n_ok = sum(1 for r in results if \"error\" not in r)\n",
    "print(f\"[MC] Completed {n_ok}/{len(results)} runs OK\")\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flovopy_plus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
